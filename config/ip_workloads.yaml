# SPDX-FileCopyrightText: (C) 2025 Tenstorrent AI ULC
# SPDX-License-Identifier: Apache-2.0
workloads:
  - api: TTSIM
    name: YOLOv7
    basedir: workloads
    module : YOLO7@Yolo_v7.py
    instances:
      yolov7-tiny      : {yaml_cfg_path: 'https://raw.githubusercontent.com/WongKinYiu/yolov7/refs/heads/main/cfg/deploy/yolov7-tiny.yaml',      in_channels: 3, in_resolution: 640, bs: 1}
      yolov7-tiny-silu : {yaml_cfg_path: 'https://raw.githubusercontent.com/WongKinYiu/yolov7/refs/heads/main/cfg/deploy/yolov7-tiny-silu.yaml', in_channels: 3, in_resolution: 640, bs: 1}
      yolov7           : {yaml_cfg_path: 'https://raw.githubusercontent.com/WongKinYiu/yolov7/refs/heads/main/cfg/deploy/yolov7.yaml',           in_channels: 3, in_resolution: 640, bs: 1}
      yolov7x          : {yaml_cfg_path: 'https://raw.githubusercontent.com/WongKinYiu/yolov7/refs/heads/main/cfg/deploy/yolov7x.yaml',          in_channels: 3, in_resolution: 640, bs: 1}

  - api: TTSIM
    name: YOLOv8
    basedir: workloads
    module : YOLO8@Yolo_v8.py
    instances:
      yolov8s          : {yaml_cfg_path: 'https://raw.githubusercontent.com/autogyro/yolo-V8/refs/heads/main/ultralytics/models/v8/yolov8s.yaml', in_channels: 3, in_resolution: 640, bs: 1}
      yolov8n          : {yaml_cfg_path: 'https://raw.githubusercontent.com/autogyro/yolo-V8/refs/heads/main/ultralytics/models/v8/yolov8n.yaml', in_channels: 3, in_resolution: 640, bs: 1}
      yolov8m          : {yaml_cfg_path: 'https://raw.githubusercontent.com/autogyro/yolo-V8/refs/heads/main/ultralytics/models/v8/yolov8m.yaml', in_channels: 3, in_resolution: 640, bs: 1}
      # yolov8l          : {yaml_cfg_path: 'https://raw.githubusercontent.com/autogyro/yolo-V8/refs/heads/main/ultralytics/models/v8/yolov8l.yaml', in_channels: 3, in_resolution: 640, bs: 1}
      # yolov8x          : {yaml_cfg_path: 'https://raw.githubusercontent.com/autogyro/yolo-V8/refs/heads/main/ultralytics/models/v8/yolov8x.yaml', in_channels: 3, in_resolution: 640, bs: 1}
      # yolov8x6         : {yaml_cfg_path: 'https://raw.githubusercontent.com/autogyro/yolo-V8/refs/heads/main/ultralytics/models/v8/yolov8x6.yaml', in_channels: 3, in_resolution: 640, bs: 1}

  - api: TTSIM
    name: RESNET50
    basedir: workloads
    module : ResNet@basicresnet.py
    params : {layers: [3,4,6,3], num_classes: 1000, num_channels: 3, use_adaptive_pool: true, init_stride: 4, bs: 1}
    instances:
      rn50_b1_hd : { img_height: 1024, img_width: 1024 }
      rn50_b1_uhd: { img_height: 2828, img_width: 2828 }

  # generate resnet50.onnx using code in workloads/onnx/examples/:
  - api: ONNX
    name: RESNET50
    basedir: workloads
    module : ResNet@basicresnet.py
    instances:
      rn50_b1_hd : { path: 'onnx/resnet50.onnx', img_height: 1024, img_width: 1024, bs: 1 }

  # generate bert-fixed-128.onnx using code in workloads/onnx/examples/:
  - api: ONNX
    name: BERT-BASE
    basedir: workloads
    module : BasicLLM@BasicLLM.py
    instances:
      bert_base : { path: 'onnx/bert-fixed-128.onnx', seq_len: 128, bs: 1 }

  - api: ONNX
    name: VIT-BASE
    basedir: workloads/onnx
    module: vit-base-fixed-224.onnx
    instances:
      default: { path: vit-base-fixed-224.onnx,
                 bs: 8,
                 img_height: 224,
                 img_width: 224 }

  - api: ONNX
    name: UNET-BASE
    basedir: workloads/onnx
    module: unet-fixed-256.onnx
    instances:
      default: { path: unet-fixed-256.onnx,
                 bs: 1,
                 img_height: 256,
                 img_width: 256 }

  - api: ONNX
    name: LLAMA3_1B
    basedir: workloads/onnx
    module: llama3_1b_fixed-128.onnx
    instances:
      default: { path: llama3_1b_fixed-128.onnx,
                 bs: 1,
                 seq_len: 128 }

  - api: ONNX
    name: LLAMA3_3B
    basedir: workloads/onnx
    module: llama3_3b_fixed-128.onnx
    instances:
      default: { path: llama3_3b_fixed-128.onnx,
                 bs: 1,
                 seq_len: 128 }

  - api: ONNX
    name: LLAMA3_8B
    basedir: workloads/onnx
    module: llama3_8b_fixed-128.onnx
    instances:
      default: { path: llama3_8b_fixed-128.onnx,
                 bs: 1,
                 seq_len: 128 }

  - api: ONNX
    name: MAMBA_2.8B
    basedir: workloads/onnx
    module: mamba_2.8b_fixed-128.onnx
    instances:
      default: { path: mamba_2.8b_fixed-128.onnx,
                 bs: 1,
                 seq_len: 128 }

  - api: TTSIM
    name: BEVDepth
    basedir: workloads/bevdepth
    module : BaseBEVDepth@BEVDepth.py
    params :
      is_train_depth    : false
      training          : false
      num_cameras       : 1
      num_sweeps        : 2
      head_conf_yaml    : config/bevdepth_cfgs/bevdepth_head.yaml
      backbone_conf_yaml: config/bevdepth_cfgs/bevdepth_backbone.yaml
    instances:
      bevdepth_s : { img_height:   32, img_width:   32, img_channels: 3, bs: 1 }
      bevdepth_m : { img_height:  256, img_width:  256, img_channels: 3, bs: 1 }
      bevdepth_l : { img_height: 1024, img_width: 1024, img_channels: 3, bs: 1 }

  - api: TTSIM
    name: UNet
    basedir: workloads/UNet
    module : UNet@unet_model.py
    instances:
      unet_b1 : {n_channels: 3, n_classes: 2, img_size: 256, bilinear: False, bs: 1}

  - api: TTSIM
    name: llama2
    basedir: workloads/llama2
    module : Transformer@model.py
    instances:
      input_small: {dim: 32, n_layers: 2, n_heads: 2, vocab_size: 256, max_batch_size: 2, max_seq_len: 8, seq_len: 1, bs: 1}
      input_standard: {dim: 4096, n_layers: 32, n_heads: 32, vocab_size: 32000, max_batch_size: 2, max_seq_len: 8, seq_len: 1, bs: 1}

  - api: TTSIM
    name: SwinTransformer
    basedir: workloads/Swin-Transformer
    module : SwinTransformer@SwinTransformer.py
    instances:
      input_1: {img_size: 224, in_chans: 3, bs: 3, num_classes: 3000}

  - api: TTSIM
    name: LeViT
    basedir: workloads/LeViT
    module : LEVIT@LeViT.py
    instances:
      LeViT_128S: { img_height: 224, img_width: 224, img_channels: 3, bs: 1, patch_size: 16, dims: [128, 256, 384], depths: [2, 3, 4], heads: [4, 6, 8], key_dim: [16, 16, 16], attn_ratio: [2, 2, 2], mlp_ratio: [2, 2, 2], down_ops: [["Subsample", 16, 8, 4, 2, 2], ["Subsample", 16, 16, 4, 2, 2]], drop_path: 0, global_pool: avg, compute_pipe: matrix }
      LeViT_128: { img_height: 224, img_width: 224, img_channels: 3, bs: 1, patch_size: 16, dims: [128, 256, 384], depths: [4, 4, 4], heads: [4, 8, 12], key_dim: [16, 16, 16], attn_ratio: [2, 2, 2], mlp_ratio: [2, 2, 2], down_ops: [["Subsample", 16, 8, 4, 2, 2], ["Subsample", 16, 16, 4, 2, 2]], drop_path: 0, global_pool: avg, compute_pipe: matrix }
      LeViT_192: { img_height: 224, img_width: 224, img_channels: 3, bs: 1, patch_size: 16, dims: [192, 288, 384], depths: [4, 4, 4], heads: [3, 5, 6], key_dim: [32, 32, 32], attn_ratio: [2, 2, 2], mlp_ratio: [2, 2, 2], down_ops: [["Subsample", 32, 6, 4, 2, 2], ["Subsample", 32, 9, 4, 2, 2]], drop_path: 0, global_pool: avg, compute_pipe: matrix }
      LeViT_256: { img_height: 224, img_width: 224, img_channels: 3, bs: 1, patch_size: 16, dims: [256, 384, 512], depths: [4, 4, 4], heads: [4, 6, 8], key_dim: [32, 32, 32], attn_ratio: [2, 2, 2], mlp_ratio: [2, 2, 2], down_ops: [["Subsample", 32, 8, 4, 2, 2], ["Subsample", 32, 12, 4, 2, 2]], drop_path: 0, global_pool: avg, compute_pipe: matrix }
      LeViT_384: { img_height: 224, img_width: 224, img_channels: 3, bs: 1, patch_size: 16, dims: [384, 512, 768], depths: [6, 9, 12], heads: [6, 9, 12], key_dim: [32, 32, 32], attn_ratio: [2, 2, 2], mlp_ratio: [2, 2, 2], down_ops: [["Subsample", 32, 12, 4, 2, 2], ["Subsample", 32, 16, 4, 2, 2]], drop_path: 0.1, global_pool: avg, compute_pipe: matrix }

  - api: TTSIM
    name: EfficientViT_CLS
    basedir: workloads/EfficientViT
    module: EFFICIENTVIT@EfficientViT_Cls.py
    instances:
      EfficientViT_CLS_B0: { img_height: 224, img_width: 224, img_channels: 3, bs: 1, num_classes: 1000,
        stage_res: [56, 28, 14, 7], dims: [8, 16, 32, 64], blocks: [1, 2, 2, 2],
        stem_out: 8, head_in: 128, head_widths: [1024, 1280], activation: hswish,
        global_pool: avg, compute_pipe: matrix, model_size: small }

      EfficientViT_CLS_B1: { img_height: 224, img_width: 224, img_channels: 3, bs: 1, num_classes: 1000,
        stage_res: [56, 28, 14, 7], dims: [16, 32, 64, 128], blocks: [1, 2, 3, 4],
        stem_out: 16, head_in: 256, head_widths: [1536, 1600], activation: hswish,
        global_pool: avg, compute_pipe: matrix, model_size: small }

      EfficientViT_CLS_B2: { img_height: 224, img_width: 224, img_channels: 3, bs: 1, num_classes: 1000,
        stage_res: [56, 28, 14, 7], dims: [24, 48, 96, 192], blocks: [1, 3, 4, 6],
        stem_out: 24, head_in: 384, head_widths: [2304, 2560], activation: hswish,
        global_pool: avg, compute_pipe: matrix, model_size: small }

      EfficientViT_CLS_B3: { img_height: 224, img_width: 224, img_channels: 3, bs: 1, num_classes: 1000,
        stage_res: [56, 28, 14, 7], dims: [32, 64, 128, 256], blocks: [1, 4, 6, 9],
        stem_out: 32, head_in: 512, head_widths: [2304, 2560], activation: hswish,
        global_pool: avg, compute_pipe: matrix, model_size: small }

      EfficientViT_CLS_L1: { img_height: 224, img_width: 224, img_channels: 3, bs: 1, num_classes: 1000,
        stage_res: [56, 28, 14, 7], dims: [64, 128, 256, 512], blocks: [1, 1, 6, 6],
        stem_out: 32, head_in: 512, head_widths: [3072, 3200], activation: gelu,
        global_pool: avg, compute_pipe: matrix, model_size: large }

      EfficientViT_CLS_L2: { img_height: 224, img_width: 224, img_channels: 3, bs: 1, num_classes: 1000,
        stage_res: [56, 28, 14, 7], dims: [64, 128, 256, 512], blocks: [1, 2, 8, 8],
        stem_out: 32, head_in: 512, head_widths: [3072, 3200], activation: gelu,
        global_pool: avg, compute_pipe: matrix, model_size: large }

      EfficientViT_CLS_L3: { img_height: 224, img_width: 224, img_channels: 3, bs: 1, num_classes: 1000,
        stage_res: [56, 28, 14, 7], dims: [80, 224, 384, 1024], blocks: [3, 4, 8, 3],
        stem_out: 48, head_in: 1024, head_widths: [6144, 6400], activation: gelu,
        global_pool: avg, compute_pipe: matrix, model_size: large }
  
  - api: TTSIM
    name: EfficientViT_SEG
    basedir: workloads/EfficientViT
    module: EFFICIENTVIT_SEG@EfficientViT_Seg.py
    instances:
      # ---- Cityscapes (n_classes=19); matches seg.py exactly (OS=8 => 64x64 at 512x512) ----
      EfficientViT_SEG_B0_CITY: { img_height: 512, img_width: 512, img_channels: 3, bs: 1,
        dims: [32, 64, 128, 128], blocks: [1, 2, 2, 2], stem_out: 16, activation: hswish,
        fid_list: [stage4, stage3, stage2], in_channel_list: auto, stride_list: [16, 8, 4],
        head_stride: 8, head_width: 32, head_depth: 1, expand_ratio: 4, middle_op: mbconv, final_expand: 4,
        n_classes: 19, compute_pipe: matrix }

      EfficientViT_SEG_B1_CITY: { img_height: 512, img_width: 512, img_channels: 3, bs: 1,
        dims: [32, 64, 128, 256], blocks: [1, 3, 3, 3], stem_out: 16, activation: hswish,
        fid_list: [stage4, stage3, stage2], in_channel_list: auto, stride_list: [16, 8, 4],
        head_stride: 8, head_width: 64, head_depth: 3, expand_ratio: 4, middle_op: mbconv, final_expand: 4,
        n_classes: 19, compute_pipe: matrix }

      EfficientViT_SEG_B2_CITY: { img_height: 512, img_width: 512, img_channels: 3, bs: 1,
        dims: [32, 64, 128, 384], blocks: [2, 3, 6, 4], stem_out: 16, activation: hswish,
        fid_list: [stage4, stage3, stage2], in_channel_list: auto, stride_list: [16, 8, 4],
        head_stride: 8, head_width: 96, head_depth: 3, expand_ratio: 4, middle_op: mbconv, final_expand: 4,
        n_classes: 19, compute_pipe: matrix }

      EfficientViT_SEG_B3_CITY: { img_height: 512, img_width: 512, img_channels: 3, bs: 1,
        dims: [32, 64, 160, 512], blocks: [2, 4, 8, 4], stem_out: 24, activation: hswish,
        fid_list: [stage4, stage3, stage2], in_channel_list: auto, stride_list: [16, 8, 4],
        head_stride: 8, head_width: 128, head_depth: 3, expand_ratio: 4, middle_op: mbconv, final_expand: 4,
        n_classes: 19, compute_pipe: matrix }

      EfficientViT_SEG_L1_CITY: { img_height: 512, img_width: 512, img_channels: 3, bs: 1,
        dims: [64, 128, 256, 512], blocks: [2, 3, 4, 3], stem_out: 32, activation: gelu,
        fid_list: [stage4, stage3, stage2], in_channel_list: auto, stride_list: [16, 8, 4],
        head_stride: 8, head_width: 256, head_depth: 3, expand_ratio: 1, middle_op: fmbconv, final_expand: null,
        n_classes: 19, compute_pipe: matrix }

      EfficientViT_SEG_L2_CITY: { img_height: 512, img_width: 512, img_channels: 3, bs: 1,
        dims: [64, 160, 320, 512], blocks: [2, 3, 5, 4], stem_out: 32, activation: gelu,
        fid_list: [stage4, stage3, stage2], in_channel_list: auto, stride_list: [16, 8, 4],
        head_stride: 8, head_width: 256, head_depth: 5, expand_ratio: 1, middle_op: fmbconv, final_expand: null,
        n_classes: 19, compute_pipe: matrix }

      #---- ADE20K (n_classes=150); matches seg.py (note final_expand differences) ----
      EfficientViT_SEG_B1_ADE: { img_height: 512, img_width: 512, img_channels: 3, bs: 1,
        dims: [32, 64, 128, 256], blocks: [1, 3, 3, 3], stem_out: 16, activation: hswish,
        fid_list: [stage4, stage3, stage2], in_channel_list: auto, stride_list: [16, 8, 4],
        head_stride: 8, head_width: 64, head_depth: 3, expand_ratio: 4, middle_op: mbconv, final_expand: null,
        n_classes: 150, compute_pipe: matrix }

      EfficientViT_SEG_B2_ADE: { img_height: 512, img_width: 512, img_channels: 3, bs: 1,
        dims: [32, 64, 128, 384], blocks: [2, 3, 6, 4], stem_out: 16, activation: hswish,
        fid_list: [stage4, stage3, stage2], in_channel_list: auto, stride_list: [16, 8, 4],
        head_stride: 8, head_width: 96, head_depth: 3, expand_ratio: 4, middle_op: mbconv, final_expand: null,
        n_classes: 150, compute_pipe: matrix }

      EfficientViT_SEG_B3_ADE: { img_height: 512, img_width: 512, img_channels: 3, bs: 1,
        dims: [32, 64, 160, 512], blocks: [2, 4, 8, 4], stem_out: 24, activation: hswish,
        fid_list: [stage4, stage3, stage2], in_channel_list: auto, stride_list: [16, 8, 4],
        head_stride: 8, head_width: 128, head_depth: 3, expand_ratio: 4, middle_op: mbconv, final_expand: null,
        n_classes: 150, compute_pipe: matrix }

      EfficientViT_SEG_L1_ADE: { img_height: 512, img_width: 512, img_channels: 3, bs: 1,
        dims: [64, 128, 256, 512], blocks: [2, 3, 4, 3], stem_out: 32, activation: gelu,
        fid_list: [stage4, stage3, stage2], in_channel_list: auto, stride_list: [16, 8, 4],
        head_stride: 8, head_width: 128, head_depth: 3, expand_ratio: 4, middle_op: fmbconv, final_expand: 8,
        n_classes: 150, compute_pipe: matrix }

      EfficientViT_SEG_L2_ADE: { img_height: 512, img_width: 512, img_channels: 3, bs: 1,
        dims: [64, 160, 320, 512], blocks: [2, 3, 5, 4], stem_out: 32, activation: gelu,
        fid_list: [stage4, stage3, stage2], in_channel_list: auto, stride_list: [16, 8, 4],
        head_stride: 8, head_width: 128, head_depth: 3, expand_ratio: 4, middle_op: fmbconv, final_expand: 8,
        n_classes: 150, compute_pipe: matrix }

  - api: TTSIM
    name: SDv1p5
    basedir: workloads/diffusers
    module : SDModel@stablediffusion.py
    instances:
      sd_b1 : {bs: 1}

  - api: TTSIM
    name: RetinaNet
    basedir: workloads/Retinanet
    module : RetinaNet@model.py
    params : {num_classes: 80, img_size: 608, resnet_depth: 50}
    instances:
      retinanet_rn50_608: {bs: 1}
